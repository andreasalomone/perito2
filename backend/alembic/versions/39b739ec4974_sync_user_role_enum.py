"""sync_user_role_enum

Revision ID: 39b739ec4974
Revises: 9db07502eeea
Create Date: 2025-12-04 11:05:21.449535

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '39b739ec4974'
down_revision: Union[str, Sequence[str], None] = '9db07502eeea'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Create ENUM types if they don't exist
    user_role_enum = postgresql.ENUM('ADMIN', 'MEMBER', name='userrole')
    user_role_enum.create(op.get_bind(), checkfirst=True)

    case_status_enum = postgresql.ENUM('OPEN', 'CLOSED', 'ARCHIVED', name='casestatus')
    case_status_enum.create(op.get_bind(), checkfirst=True)

    # op.drop_index(op.f('idx_outbox_pending'), table_name='outbox_messages', postgresql_where="((status)::text = 'PENDING'::text)")
    # op.drop_table('outbox_messages')
    
    # Drop defaults first to avoid casting errors
    op.execute("ALTER TABLE allowed_emails ALTER COLUMN role DROP DEFAULT")
    op.execute("ALTER TABLE cases ALTER COLUMN status DROP DEFAULT")

    op.alter_column('allowed_emails', 'role',
               existing_type=sa.VARCHAR(length=50),
               type_=sa.Enum('ADMIN', 'MEMBER', name='userrole'),
               nullable=False,
               server_default='MEMBER',
               existing_server_default=sa.text("'member'::character varying"),
               postgresql_using="role::userrole")
    op.alter_column('allowed_emails', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.alter_column('audit_logs', 'details',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.drop_index(op.f('idx_audit_logs_org_created'), table_name='audit_logs')
    op.drop_index(op.f('idx_audit_logs_user'), table_name='audit_logs')
    op.alter_column('cases', 'status',
               existing_type=sa.VARCHAR(length=50),
               type_=sa.Enum('OPEN', 'CLOSED', 'ARCHIVED', name='casestatus'),
               existing_nullable=False,
               server_default='OPEN',
               existing_server_default=sa.text("'OPEN'::character varying"),
               postgresql_using="status::casestatus")
    op.drop_index(op.f('idx_cases_dashboard'), table_name='cases')
    op.alter_column('clients', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.alter_column('documents', 'ai_extracted_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.drop_index(op.f('idx_documents_case'), table_name='documents')
    op.alter_column('ml_training_pairs', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.drop_index(op.f('idx_ml_pairs_case'), table_name='ml_training_pairs')
    op.alter_column('organizations', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.alter_column('report_versions', 'is_final',
               existing_type=sa.BOOLEAN(),
               nullable=True,
               existing_server_default=sa.text('false'))
    op.alter_column('report_versions', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True)
    op.drop_index(op.f('idx_report_versions_case'), table_name='report_versions')
    op.drop_constraint(op.f('uq_report_versions_case_ver'), 'report_versions', type_='unique')
    op.drop_index(op.f('idx_users_org'), table_name='users')
    op.drop_constraint(op.f('users_email_key'), 'users', type_='unique')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_unique_constraint(op.f('users_email_key'), 'users', ['email'])
    op.create_index(op.f('idx_users_org'), 'users', ['organization_id'], unique=False)
    op.create_unique_constraint(op.f('uq_report_versions_case_ver'), 'report_versions', ['case_id', 'version_number'])
    op.create_index(op.f('idx_report_versions_case'), 'report_versions', ['case_id'], unique=False)
    op.alter_column('report_versions', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('report_versions', 'is_final',
               existing_type=sa.BOOLEAN(),
               nullable=False,
               existing_server_default=sa.text('false'))
    op.alter_column('organizations', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.create_index(op.f('idx_ml_pairs_case'), 'ml_training_pairs', ['case_id'], unique=False)
    op.alter_column('ml_training_pairs', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.create_index(op.f('idx_documents_case'), 'documents', ['case_id'], unique=False)
    op.alter_column('documents', 'ai_extracted_data',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('clients', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.create_index(op.f('idx_cases_dashboard'), 'cases', ['organization_id', sa.literal_column('created_at DESC')], unique=False)
    op.alter_column('cases', 'status',
               existing_type=sa.Enum('OPEN', 'CLOSED', 'ARCHIVED', name='casestatus'),
               type_=sa.VARCHAR(length=50),
               existing_nullable=False,
               existing_server_default=sa.text("'OPEN'::character varying"))
    op.create_index(op.f('idx_audit_logs_user'), 'audit_logs', ['user_id'], unique=False)
    op.create_index(op.f('idx_audit_logs_org_created'), 'audit_logs', ['organization_id', sa.literal_column('created_at DESC')], unique=False)
    op.alter_column('audit_logs', 'details',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('allowed_emails', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True)
    op.alter_column('allowed_emails', 'role',
               existing_type=sa.Enum('ADMIN', 'MEMBER', 'SURVEYOR', name='userrole'),
               type_=sa.VARCHAR(length=50),
               nullable=True,
               existing_server_default=sa.text("'member'::character varying"))
    op.create_table('outbox_messages',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('topic', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('payload', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('status', sa.VARCHAR(), server_default=sa.text("'PENDING'::character varying"), autoincrement=False, nullable=False),
    sa.Column('retry_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('processed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('error_log', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('outbox_messages_pkey'))
    )
    op.create_index(op.f('idx_outbox_pending'), 'outbox_messages', ['created_at'], unique=False, postgresql_where="((status)::text = 'PENDING'::text)")
    # ### end Alembic commands ###
